{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune your preprocessing steps and algorithm selection like hyperparameters \n",
    "\n",
    "Using a pipeline to preprocess your data offers some substantive [advantages](https://moritzkoerber.github.io/python/tutorial/2019/10/11/blogpost/). A pipeline guarantees that no information from the test set is used in preprocessing or training the model. Pipelines are often combined with cross-validation to find the best parameter combination of a machine learning algorithm. However, the implemented preprocessing steps, for example whether to scale the data, or the implemented machine learning algorithm can also be seen as a hyperparameter; not of a single model but of the whole training process. We can therefore tune them as such to further improve our model's performance. In this post, I will show you how to do it with sci-kit learn! \n",
    "\n",
    "We start with the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RepeatedStratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are again working with the Titanic data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Mahon Miss. Bridget Delia</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330924</td>\n",
       "      <td>7.8792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Clifford Mr. George Quincy</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>110465</td>\n",
       "      <td>52.0000</td>\n",
       "      <td>A14</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Stoughton MA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Yasbeck Mr. Antoni</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2659</td>\n",
       "      <td>14.4542</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Tenglin Mr. Gunnar Isidor</td>\n",
       "      <td>male</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>350033</td>\n",
       "      <td>7.7958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>13 15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Kelly Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass  survived                        name     sex   age  sibsp  parch  \\\n",
       "0       3         0   Mahon Miss. Bridget Delia  female   NaN      0      0   \n",
       "1       1         0  Clifford Mr. George Quincy    male   NaN      0      0   \n",
       "2       3         0          Yasbeck Mr. Antoni    male  27.0      1      0   \n",
       "3       3         1   Tenglin Mr. Gunnar Isidor    male  25.0      0      0   \n",
       "4       3         0             Kelly Mr. James    male  34.5      0      0   \n",
       "\n",
       "   ticket     fare cabin embarked   boat  body     home.dest  \n",
       "0  330924   7.8792   NaN        Q    NaN   NaN           NaN  \n",
       "1  110465  52.0000   A14        S    NaN   NaN  Stoughton MA  \n",
       "2    2659  14.4542   NaN        C      C   NaN           NaN  \n",
       "3  350033   7.7958   NaN        S  13 15   NaN           NaN  \n",
       "4  330911   7.8292   NaN        Q    NaN  70.0           NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic = pd.read_csv('./titanic.csv')\n",
    "\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we we will use the test data (in cross-validation) to make model-relevant decisions, such as what preprocessing steps we should perform, we need fresh, yet unseen data to obtain a valid estimate of our final model's out-of-sample performance. This is the same reason why we perform cross-validation in the first place! Nested cross-validation is an option here, but I leave it to creating a final hold-out set here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "X = titanic.drop('survived', axis = 1)\n",
    "y = titanic.survived\n",
    "\n",
    "X_train, X_holdout, y_train, y_holdout = train_test_split(X, y, stratify = y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Following the last post](https://moritzkoerber.github.io/python/tutorial/2019/10/11/blogpost/), we create a pipeline including a ColumnTransformer ('preprocessor') that imputes the missing values, creates dummy variables for the categorical features and scales the numeric features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "categorical_features = ['pclass', 'sex', 'embarked']\n",
    "categorical_transformer = Pipeline(\n",
    "    [\n",
    "        ('imputer_cat', SimpleImputer(strategy = 'constant', fill_value = 'missing')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown = 'ignore'))\n",
    "    ]\n",
    ")\n",
    "\n",
    "numeric_features = ['age', 'sibsp', 'parch', 'fare']\n",
    "numeric_transformer = Pipeline(\n",
    "    [\n",
    "        ('imputer_num', SimpleImputer()),\n",
    "        ('scaler', StandardScaler())\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        ('categoricals', categorical_transformer, categorical_features),\n",
    "        ('numericals', numeric_transformer, numeric_features)\n",
    "    ],\n",
    "    remainder = 'drop'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the end, we include this preprocessor in our pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    [\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('clf', LogisticRegression())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning the machine learning algorithm\n",
    "\n",
    "The same way we provide a list of hyperparameters of a machine learning algorithm in a parameter grid to find the best parameter combination, we can also fill in the machine learning algorithm itself as a \"hyperparameter\". `('clf', LogisticRegression())`above is simply a placeholder where other machine learning algorithms can be filled in. In the grid below, I first try out a logistic regression and, second, a random forest classifier. Note that the parameters need to be a list of dictionaries because both models possess different parameter values to tune."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "params = [\n",
    "    {\n",
    "        'clf': [LogisticRegression()],   \n",
    "        'clf__solver': ['liblinear'],\n",
    "        'clf__penalty': ['l1', 'l2'],\n",
    "        'clf__C': [0.01, 0.1, 1, 10, 100],\n",
    "        'clf__random_state': [42],\n",
    "    },\n",
    "    {\n",
    "        'clf': [RandomForestClassifier()],\n",
    "        'clf__n_estimators': [5, 50, 100, 250],\n",
    "        'clf__max_depth': [5, 8, 10],\n",
    "        'clf__random_state': [42],\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning the preprocessing steps\n",
    "\n",
    "Next, we take care of tuning the preprocessing steps. We add them as parameters in the parameter grid by inserting their names given in the pipeline above: The `StandardScaler()` to preprocess numericals can be addressed by `'preprocessing__numericals__scaler'`. `'preprocessing'` addresses the pipeline step, which is our ColumnTransformer, `'__numericals'` adresses the pipeline for numericals inside this ColumnTransformer, and `'__scaler'` addresses the StandardScaler in this particular pipeline. We could modify the StandardScaler here, for example by giving `'preprocessing__scaler__with_std': ['False']`, but we can also set whether standardizing is performed at all. By passing the list `[StandardScaler(), 'passthrough']` to the `'scaler'` step, we either use the `StandardScaler()` in this step or no transformer at all (with `'passthrough'`). By this, we can evaluate how our model performance changes if we do not standardize at all! The same is true for the imputer: We can try out whether the mean or median deliver better performance in this particular cross-validation process. \n",
    "\n",
    "Below you find the complete parameter grid with all mentioned parameters included:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "params = [\n",
    "    {\n",
    "        'clf': [LogisticRegression()],   \n",
    "        'clf__solver': ['liblinear'],\n",
    "        'clf__penalty': ['l1', 'l2'],\n",
    "        'clf__C': [0.01, 0.1, 1, 10, 100],\n",
    "        'clf__random_state': [42],\n",
    "        'preprocessing__numericals__scaler': [StandardScaler(), 'passthrough'],\n",
    "        'preprocessing__numericals__imputer_num__strategy': ['mean', 'median']\n",
    "    },\n",
    "    {\n",
    "        'clf': [RandomForestClassifier()],\n",
    "        'clf__n_estimators': [5, 50, 100, 250],\n",
    "        'clf__max_depth': [5, 8, 10],\n",
    "        'clf__random_state': [42],\n",
    "        'preprocessing__numericals__scaler': [StandardScaler(), 'passthrough'],\n",
    "        'preprocessing__numericals__imputer_num__strategy': ['mean', 'median']\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One last thing: If you wish to modify the `StandardScaler()`, e. g. by setting `with_mean`, you would need to do this at the last point where you declare what to fill into the `'scaler'` step. Here, this would be `'preprocessing__numericals__scaler': [StandardScaler(with_mean = False), 'passthrough']`.\n",
    "\n",
    "Let's see what preprocessing steps and machine learning algorithm performs best:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1-score: 0.722\n",
      "\n",
      "Best parameter set: {'clf': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=8, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=50,\n",
      "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
      "                       warm_start=False), 'clf__max_depth': 8, 'clf__n_estimators': 50, 'clf__random_state': 42, 'preprocessing__numericals__imputer_num__strategy': 'median', 'preprocessing__numericals__scaler': StandardScaler(copy=True, with_mean=True, with_std=True)}\n",
      "\n",
      "Scores:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91       647\n",
      "           1       0.91      0.77      0.83       400\n",
      "\n",
      "    accuracy                           0.88      1047\n",
      "   macro avg       0.89      0.86      0.87      1047\n",
      "weighted avg       0.88      0.88      0.88      1047\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rskf = RepeatedStratifiedKFold(n_splits = 5, n_repeats = 2, random_state = 42)\n",
    "\n",
    "cv = GridSearchCV(pipeline, params, cv = rskf, scoring = ['f1', 'accuracy'], refit = 'f1', n_jobs = -1)\n",
    "\n",
    "cv.fit(X_train, y_train)\n",
    "\n",
    "print(f'Best F1-score: {cv.best_score_:.3f}\\n')\n",
    "print(f'Best parameter set: {cv.best_params_}\\n')\n",
    "print(f'Scores: {classification_report(y_train, cv.predict(X_train))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our best estimator is a random forest with `max_depth = 8`, `n_estimators = 50`, imputation by median and standardized numericals. \n",
    "\n",
    "How do we do on completely new, yet unseen data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.88      0.86       162\n",
      "           1       0.79      0.71      0.75       100\n",
      "\n",
      "    accuracy                           0.82       262\n",
      "   macro avg       0.81      0.80      0.80       262\n",
      "weighted avg       0.82      0.82      0.81       262\n",
      "\n",
      "\n",
      "F1-score: 0.747\n"
     ]
    }
   ],
   "source": [
    "preds = cv.predict(X_holdout)\n",
    "print(f'Scores: {classification_report(y_holdout, preds)}\\n')\n",
    "print(f'F1-score: {f1_score(y_holdout, preds):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be some room for improvement!\n",
    "\n",
    "Find the complete code in one single file here:"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "nteract": {
   "version": "0.15.0"
  },
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
